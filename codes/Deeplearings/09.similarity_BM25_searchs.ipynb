{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 정보검색을 키워드 중심 활용\n- BM25(Best Matching 25)는 정보 검색에 널리 사용, 랭킹 함수","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nfrom typing import List\nfrom transformers import PreTrainedTokenizer\nfrom collections import defaultdict\n\nclass BM25:\n    def __init__(self, corpus: List[List[str]], tokenizer: PreTrainedTokenizer):\n        # Initialize BM25 with a list of tokenized documents and a tokenizer.\n        self.tokenizer = tokenizer\n        self.corpus = corpus\n        \n        # Tokenize the entire corpus. This converts words into token IDs.\n        self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n        \n        # Number of documents in the corpus.\n        self.n_docs = len(self.tokenized_corpus)\n\n        # Calculate the average document length in tokens.\n        self.avg_doc_lens = sum(len(doc) for doc in self.tokenized_corpus) / self.n_docs\n\n        # Compute the Inverse Document Frequency (IDF) values.\n        self.idf = self._calculate_idf()\n\n        # Compute the term frequencies for each document.\n        self.term_freqs = self._calculate_term_freqs()\n\n    def _calculate_idf(self):\n        # Calculate Inverse Document Frequency (IDF) for each unique token in the corpus.\n        idf = defaultdict(float)\n        \n        # Count the number of documents containing each token.\n        for doc in self.tokenized_corpus:\n            for token_id in set(doc):\n                idf[token_id] += 1\n\n        # Apply the BM25-specific IDF formula for each token.\n        for token_id, doc_frequency in idf.items():\n            idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n        \n        return idf\n\n    def _calculate_term_freqs(self):\n        # Compute the frequency of each token in each document.\n        term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n        \n        for i, doc in enumerate(self.tokenized_corpus):\n            for token_id in doc:\n                term_freqs[i][token_id] += 1\n\n        return term_freqs\n\n    def get_scores(self, query: str, k1: float = 1.2, b: float = 0.75):\n        # Calculate BM25 scores for all documents given a query.\n        # k1 controls term frequency saturation; b adjusts document length normalization.\n        query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n        scores = np.zeros(self.n_docs)\n\n        # Compute BM25 scores for each query token.\n        for q in query:\n            idf = self.idf[q]  # Retrieve the precomputed IDF for the query token.\n\n            for i, term_freq in enumerate(self.term_freqs):\n                q_frequency = term_freq[q]  # Term frequency of the query token in the current document.\n                doc_len = len(self.tokenized_corpus[i])\n\n                # BM25 formula to compute the score contribution of this token.\n                score_q = idf * (q_frequency * (k1 + 1)) / (q_frequency + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n\n                # Accumulate the score for document i.\n                scores[i] += score_q\n\n        return scores\n\n    def get_top_k(self, query: str, k: int):\n        # Get the top-k documents based on BM25 scores for the given query.\n        scores = self.get_scores(query)\n\n        # Sort document indices by scores in descending order and select top-k.\n        top_k_indices = np.argsort(scores)[-k:][::-1]\n        \n        # Retrieve the scores for the top-k documents.\n        top_k_scores = scores[top_k_indices]\n\n        return top_k_scores, top_k_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:14:44.348351Z","iopub.execute_input":"2025-02-07T05:14:44.348731Z","iopub.status.idle":"2025-02-07T05:14:49.291395Z","shell.execute_reply.started":"2025-02-07T05:14:44.348698Z","shell.execute_reply":"2025-02-07T05:14:49.290331Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### 데이터셋 관련","metadata":{}},{"cell_type":"markdown","source":"#### 예비 활용 연습","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n\ntext_list = ['안녕하세요', '반갑습니다.', '안녕 서울', '부산, 안녕! 안녕']\nindex_bm25 = BM25(text_list, tokenizer)\n# index_bm25\nvars(index_bm25).keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:28.390380Z","iopub.execute_input":"2025-02-07T05:32:28.390736Z","iopub.status.idle":"2025-02-07T05:32:28.860087Z","shell.execute_reply.started":"2025-02-07T05:32:28.390709Z","shell.execute_reply":"2025-02-07T05:32:28.859198Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dict_keys(['tokenizer', 'corpus', 'tokenized_corpus', 'n_docs', 'avg_doc_lens', 'idf', 'term_freqs'])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"vars(index_bm25)['tokenized_corpus'], vars(index_bm25)['n_docs'], vars(index_bm25)['avg_doc_lens']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:14.211504Z","iopub.execute_input":"2025-02-07T05:29:14.211908Z","iopub.status.idle":"2025-02-07T05:29:14.218135Z","shell.execute_reply.started":"2025-02-07T05:29:14.211874Z","shell.execute_reply":"2025-02-07T05:29:14.217201Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"([[5891, 2205, 5971], [9927, 2219, 3606, 18], [1378, 2440, 3671]],\n 3,\n 3.3333333333333335)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"vars(index_bm25)['idf'], vars(index_bm25)['term_freqs']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:31.643802Z","iopub.execute_input":"2025-02-07T05:32:31.644134Z","iopub.status.idle":"2025-02-07T05:32:31.651043Z","shell.execute_reply.started":"2025-02-07T05:32:31.644108Z","shell.execute_reply":"2025-02-07T05:32:31.650002Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(defaultdict(float,\n             {5971: 1.2039728043259361,\n              5891: 0.3566749439387324,\n              2205: 1.2039728043259361,\n              18: 1.2039728043259361,\n              2219: 1.2039728043259361,\n              3606: 1.2039728043259361,\n              9927: 1.2039728043259361,\n              3671: 1.2039728043259361,\n              16: 1.2039728043259361,\n              5: 1.2039728043259361,\n              3902: 1.2039728043259361}),\n [defaultdict(int, {5891: 1, 2205: 1, 5971: 1}),\n  defaultdict(int, {9927: 1, 2219: 1, 3606: 1, 18: 1}),\n  defaultdict(int, {5891: 1, 3671: 1}),\n  defaultdict(int, {3902: 1, 16: 1, 5891: 2, 5: 1})])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"index_bm25.get_scores('안녕'), index_bm25.get_top_k('안녕 광주', 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:35:55.967413Z","iopub.execute_input":"2025-02-07T05:35:55.967799Z","iopub.status.idle":"2025-02-07T05:35:55.976409Z","shell.execute_reply.started":"2025-02-07T05:35:55.967771Z","shell.execute_reply":"2025-02-07T05:35:55.975343Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(array([0.37881339, 0.        , 0.43250348, 0.43767284]),\n (array([0.43767284, 0.43250348]), array([3, 2])))"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"#### 실제 데이터 적용 확인","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# https://huggingface.co/datasets/klue/klue/viewer/mrc\nklue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\nklue_mrc_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:38:07.477970Z","iopub.execute_input":"2025-02-07T05:38:07.478339Z","iopub.status.idle":"2025-02-07T05:38:13.714014Z","shell.execute_reply.started":"2025-02-07T05:38:07.478307Z","shell.execute_reply":"2025-02-07T05:38:13.712707Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/22.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f51e5f3af947b6961fb57ab5be274d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04e66f2f79b4ba0b2c0c2a50cfe60a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/8.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45b7c49c3894223a79706e5904c6424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bc9d9259a44ee291e1b49712bdd110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09641d9698444b559c6660ddb03a70e6"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n    num_rows: 17554\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"index_bm25_klue_mrc = BM25(klue_mrc_dataset['context'], tokenizer)\nindex_bm25_klue_mrc # BM25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:39:30.358129Z","iopub.execute_input":"2025-02-07T05:39:30.358810Z","iopub.status.idle":"2025-02-07T05:39:43.578284Z","shell.execute_reply.started":"2025-02-07T05:39:30.358769Z","shell.execute_reply":"2025-02-07T05:39:43.577436Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<__main__.BM25 at 0x7a9bbae51990>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# query = '이번 연도에는 언제 비가 많이 올까 ?'\nquery = '로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?'\ntops_score, tops_ranking = index_bm25_klue_mrc.get_top_k(query, 5)\ntops_score, tops_ranking","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:45:47.333270Z","iopub.execute_input":"2025-02-07T05:45:47.333667Z","iopub.status.idle":"2025-02-07T05:45:47.859159Z","shell.execute_reply.started":"2025-02-07T05:45:47.333638Z","shell.execute_reply":"2025-02-07T05:45:47.858130Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(array([33.54588925, 21.3944501 , 15.91892909, 15.86530076, 14.96643802]),\n array([    3,  8289,  1079, 14462, 11915]))"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"for rank in tops_ranking:\n    print(klue_mrc_dataset['context'][rank][:50])\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:45:51.978093Z","iopub.execute_input":"2025-02-07T05:45:51.978471Z","iopub.status.idle":"2025-02-07T05:45:52.898008Z","shell.execute_reply.started":"2025-02-07T05:45:51.978439Z","shell.execute_reply":"2025-02-07T05:45:52.896916Z"}},"outputs":[{"name":"stdout","text":"미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n잭슨은 영국의 컴벌랜드 카운티에서 태어나 부모가 죽은 후에, 사우스캐롤라이나의 찰스턴에 이\n영국과 북미 식민지 간의 관계가 악화되어 1775년 4월에 뉴잉글랜드에서 렉싱턴 콩코드 전\n케네디는 1962년 11월 7일 테드 케네디는 연방 상원으로 선서되었다. 그는 그가 처음 \n윌리 딕슨의 블루스 천국은 미국 일리노이주 시카고에 있는 전시관 겸 공연장이다. 세계 2차\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}